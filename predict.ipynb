{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from datetime import timedelta\n",
    "import catboost as cat\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARENT_FOLDER = '../data/'\n",
    "\n",
    "\n",
    "kernel_train_path = 'memory_sample_kernel_log_round1_a_train.csv'\n",
    "failure_train_path = 'memory_sample_failure_tag_round1_a_train.csv'\n",
    "address_train_path = 'memory_sample_address_log_round1_a_train.csv'\n",
    "mce_train_path = 'memory_sample_mce_log_round1_a_train.csv'\n",
    "\n",
    "\n",
    "kernel_test_path = 'memory_sample_kernel_log_round1_b_test_0722_0731.csv'\n",
    "failure_test_path = 'memory_sample_failure_tag_round1_b_test.csv'\n",
    "address_test_path = 'memory_sample_address_log_round1_b_test_0722_0731.csv'\n",
    "mce_test_path = 'memory_sample_mce_log_round1_b_test_0722_0731.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 评分函数，引用自PAKDD2021论坛中的score_func_round2，链接见readme\n",
    "def score_func_round2(sub_df, cur_failure_tag, verbose=False):\n",
    "    '''\n",
    "    注意cur_failure_tag的时间窗口要和sub_list一样。\n",
    "    sub_list需要加一个collect_time, 表示做出预测的那一分钟, 类型为 pd.Timestamp。\n",
    "    [{\"serial_number\":server_1, \"pti\":14, 'collect_time': Timestamp('2019-08-01 05:18:00')},\n",
    "    {\"serial_number\":server_123, \"pti\":1200, 'collect_time': Timestamp('2019-08-02 00:08:00')}]\n",
    "    '''\n",
    "    if sub_df.empty:\n",
    "        print(\"[Warning] sub num 0\")\n",
    "        return 0\n",
    "    # remove invalid sub\n",
    "    # 删除 ati < 0的提交\n",
    "    sub_df = sub_df.join(cur_failure_tag.set_index('serial_number')['failure_time'], how='left', on='serial_number')\n",
    "    sub_df['ati'] = (sub_df['failure_time']-sub_df['collect_time'])/pd.Timedelta('1min')\n",
    "    sub_df = sub_df[(sub_df['ati']>=0)|(sub_df['ati'].isna())]\n",
    "    # 取每个周期第一个\n",
    "    sub_df = sub_df.sort_values(by=['serial_number', 'collect_time'])\n",
    "    pre_ser = -1\n",
    "    init_pre_time = pd.to_datetime('2018-12-01')\n",
    "    window_time = pd.Timedelta('7D')\n",
    "    pre_time = init_pre_time\n",
    "    judge = []\n",
    "    for sn, cur_time in sub_df[['serial_number', 'collect_time']].values:\n",
    "        if pre_ser != sn:\n",
    "            pre_time = init_pre_time\n",
    "        if (cur_time-pre_time) < window_time:\n",
    "            judge.append(0)\n",
    "        else:\n",
    "            judge.append(1)\n",
    "            pre_time = cur_time\n",
    "        pre_ser = sn\n",
    "    judge = np.array(judge)\n",
    "    sub_df = sub_df[judge==1].reset_index(drop=True)\n",
    "\n",
    "    # failure_time_dict = cur_failure_tag.set_index('serial_number')['failure_time'].to_dict()\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    # score\n",
    "    n_pp = len(sub_df)\n",
    "    n_pr = len(cur_failure_tag)\n",
    "\n",
    "    n_tpr = 0\n",
    "    n_tpp = 0\n",
    "    for sn, pti, ati in sub_df[['serial_number', 'pti', 'ati']].values:\n",
    "        if pd.notna(ati):\n",
    "            if 0 <= pti < 7*24*60: # 待确定\n",
    "                if pti <= ati:\n",
    "                    n_tpp += sigmoid(pti/ati)\n",
    "            if ati < 7*24*60:\n",
    "                n_tpr += 1\n",
    "    \n",
    "    precision = n_tpp/n_pp\n",
    "    recall = n_tpr/n_pr\n",
    "    if (precision+recall) == 0:\n",
    "        f1 = 0\n",
    "    else:\n",
    "        f1 = 2*(precision*recall)/(precision+recall)\n",
    "    if verbose:\n",
    "        print(f'n_tpp: {n_tpp}, n_pp: {n_pp}, precision: {precision}, n_tpr: {n_tpr}, n_pr: {n_pr}, recall: {recall}, f1: {f1}')\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_var = ['1_hwerr_f', '1_hwerr_e', '2_hwerr_c', '2_sel', '3_hwerr_n', '2_hwerr_s', '3_hwerr_m', '1_hwerr_st',\n",
    "       '1_hw_mem_c', '3_hwerr_p', '2_hwerr_ce', '3_hwerr_as', '1_ke', '2_hwerr_p', '3_hwerr_kp', '1_hwerr_fl', '3_hwerr_r', '_hwerr_cd',\n",
    "       '3_sup_mce_note', '3_cmci_sub', '3_cmci_det', '3_hwerr_pi', '3_hwerr_o', '3_hwerr_mce_l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_tag = pd.read_csv(PARENT_FOLDER+failure_train_path)\n",
    "failure_tag['failure_time']= pd.to_datetime(failure_tag['failure_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_data = pd.read_csv(PARENT_FOLDER+failure_test_path)\n",
    "failure_data['failure_time'] = pd.to_datetime(failure_data['failure_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    with open(\"p1.pickle\", \"rb\") as f:\n",
    "        model1 = pickle.load(f)\n",
    "    with open(\"p2.pickle\", \"rb\") as f:\n",
    "        model2 = pickle.load(f)\n",
    "    return model1,model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model1,model2 = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模拟线上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_bool(data):\n",
    "    if data == 1.0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def deal_pti(x):\n",
    "    if x>40:\n",
    "        return 4000\n",
    "    elif x>30:\n",
    "        return 200\n",
    "    elif x>20:\n",
    "        return 30\n",
    "    else:\n",
    "        return 10\n",
    "\n",
    "def sta_repeat(x):\n",
    "    n = 0\n",
    "    for i in set(x):\n",
    "        if x.count(i) > 1:\n",
    "            n += 1\n",
    "    return n\n",
    "\n",
    "def sta_max(x):\n",
    "    ls = []\n",
    "    for i in set(x):\n",
    "        ls.append(x.count(i))\n",
    "    return max(ls)\n",
    "\n",
    "def deal_kernel(df_kernel,agg_time,time):\n",
    "    df_kernel_new = df_kernel.copy()\n",
    "    df_kernel_new['collect_time'] = pd.to_datetime(df_kernel_new['collect_time']).dt.floor(agg_time)\n",
    "    df_kernel_new['count'+time] = 1\n",
    "    df_kernel_new = df_kernel_new.groupby(['serial_number','manufacturer','vendor','collect_time'],as_index=False).agg('sum')\n",
    "    return df_kernel_new\n",
    "\n",
    "def deal_mce(df_mce,agg_time,time):\n",
    "    df = df_mce.copy()\n",
    "    for i in [\"Z\", \"AP\", \"G\", \"F\", \"BB\", \"E\", \"CC\", \"AF\", \"AE\"]:\n",
    "        df['mca_'+i+time] = (df.mca_id == i).astype(\"float\")\n",
    "    for i in [0, 1, 2, 3]:\n",
    "        df['trans_'+str(i)+time] = (df.transaction == i).astype(\"float\")\n",
    "    df['collect_time'] = pd.to_datetime(df['collect_time']).dt.floor(agg_time)\n",
    "\n",
    "    df['count_mce_'+time] = 1\n",
    "    mce_new = df.groupby(['serial_number','manufacturer','vendor','collect_time'],as_index=False).agg('sum')\n",
    "    return mce_new\n",
    "\n",
    "def deal_address(df_address):\n",
    "    address = df_address.copy()\n",
    "    address['collect_time'] = pd.to_datetime(address['collect_time']).dt.floor('2min')\n",
    "    address_row = address[['serial_number','collect_time','row']].groupby(['serial_number','collect_time'],as_index=False).agg(list)\n",
    "    address_col = address[['serial_number','collect_time','col']].groupby(['serial_number','collect_time'],as_index=False).agg(list)\n",
    "    address_row['row_repeat'] = address_row['row'].map(sta_repeat)\n",
    "    address_col['col_repeat'] = address_col['col'].map(sta_repeat)\n",
    "    address_row['row_max'] = address_row['row'].map(sta_max)\n",
    "    address_col['col_max'] = address_col['col'].map(sta_max)\n",
    "    address_row['row_num'] = address_row['row'].apply(lambda x: len(set(x)))\n",
    "    address_col['col_num'] = address_col['col'].apply(lambda x: len(set(x)))\n",
    "    address_sta = pd.merge(address_col,address_row[['serial_number','collect_time','row_num','row_max','row_repeat']],how='left',on=['serial_number','collect_time'])\n",
    "    return address_sta\n",
    "\n",
    "def get_data(df_kernel,df_mce,df_address):\n",
    "    df_kernel_new = deal_kernel(df_kernel,'2min','2min')\n",
    "    mce_new = deal_mce(df_mce,'2min','2min')\n",
    "    address_new = deal_address(df_address)\n",
    "    kernel_sta = df_kernel_new[['serial_number','count2min']].groupby(['serial_number'],as_index=False).agg(list)\n",
    "    kernel_sta['mean_2min'] = kernel_sta['count2min'].apply(lambda x: np.mean(x))\n",
    "    kernel_sta['median_2min'] = kernel_sta['count2min'].apply(lambda x: np.median(x))\n",
    "    kernel_sta['sum_2min'] = kernel_sta['count2min'].apply(lambda x: sum(x))\n",
    "    test = pd.merge(df_kernel_new, mce_new,how='left',on=['serial_number','manufacturer','vendor','collect_time'])\n",
    "    test = pd.merge(test,kernel_sta[['serial_number','mean_2min','median_2min','sum_2min']],how='left',on=['serial_number'])\n",
    "    test = pd.merge(test,address_new,how='left',on=['serial_number','collect_time'])\n",
    "    test['vendor'] = test['vendor'].apply(lambda x: int(x))\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_test_all = pd.read_csv(PARENT_FOLDER+kernel_test_path)\n",
    "mce_test_all = pd.read_csv(PARENT_FOLDER+mce_test_path)\n",
    "address_test_all = pd.read_csv(PARENT_FOLDER+address_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_test_all['collect_time_'] = pd.to_datetime(kernel_test_all['collect_time']).dt.floor('1min')\n",
    "mce_test_all['collect_time_'] = pd.to_datetime(mce_test_all['collect_time']).dt.floor('1min')\n",
    "address_test_all['collect_time_'] = pd.to_datetime(address_test_all['collect_time']).dt.floor('1min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_test_groupby = kernel_test_all.groupby('collect_time_')\n",
    "mce_test_groupby = mce_test_all.groupby('collect_time_')\n",
    "address_test_groupby = address_test_all.groupby('collect_time_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data):\n",
    "    if data.shape[0]!=0:\n",
    "        label = model1.predict_proba(data[feats])[:,1]\n",
    "        data[\"label\"] = label\n",
    "        data_new = data[data['label']>=0.8]\n",
    "        if data_new.shape[0] == 0:\n",
    "            return pd.DataFrame([],columns=[\"serial_number\",\"collect_time\",\"pti\"])\n",
    "        else:\n",
    "            ret = model2.predict(data_new[feats])\n",
    "            data_new['reg'] = np.ceil(ret)\n",
    "            data_new['pti'] = data_new['reg'].apply(lambda x: deal_pti(x))\n",
    "            return data_new[[\"serial_number\", \"collect_time\", \"pti\"]]\n",
    "    else:\n",
    "        return pd.DataFrame([],columns=[\"serial_number\",\"collect_time\",\"pti\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = ['manufacturer', 'vendor', '1_hwerr_f','1_hwerr_e','2_hwerr_c', '3_hwerr_as','1_ke','3_hwerr_kp','3_sup_mce_note','2_hwerr_p', 'count2min',\n",
    "       'mca_Z2min', 'mca_AP2min', 'mca_G2min', 'mca_BB2min',\n",
    "       'mca_E2min', 'mca_CC2min', 'mca_AF2min',  'trans_02min',\n",
    "       'trans_12min', 'trans_22min', 'trans_32min', 'count_mce_2min',\n",
    "       'mean_2min', 'median_2min', 'sum_2min',\n",
    "       'row_num', 'row_max', 'row_repeat', 'col_num', 'col_max', 'col_repeat',\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool as ProcessPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "kernel_his = pd.DataFrame(\n",
    "                [],\n",
    "                columns=[\n",
    "                    \"collect_time\",\n",
    "                    \"1_hwerr_f\",\n",
    "                    \"1_hwerr_e\",\n",
    "                    \"2_hwerr_c\",\n",
    "                    \"2_sel\",\n",
    "                    \"3_hwerr_n\",\n",
    "                    \"2_hwerr_s\",\n",
    "                    \"3_hwerr_m\",\n",
    "                    \"1_hwerr_st\",\n",
    "                    \"1_hw_mem_c\",\n",
    "                    \"3_hwerr_p\",\n",
    "                    \"2_hwerr_ce\",\n",
    "                    \"3_hwerr_as\",\n",
    "                    \"1_ke\",\n",
    "                    \"2_hwerr_p\",\n",
    "                    \"3_hwerr_kp\",\n",
    "                    \"1_hwerr_fl\",\n",
    "                    \"3_hwerr_r\",\n",
    "                    \"_hwerr_cd\",\n",
    "                    \"3_sup_mce_note\",\n",
    "                    \"3_cmci_sub\",\n",
    "                    \"3_cmci_det\",\n",
    "                    \"3_hwerr_pi\",\n",
    "                    \"3_hwerr_o\",\n",
    "                    \"3_hwerr_mce_l\",\n",
    "                    \"serial_number\",\n",
    "                    \"manufacturer\",\n",
    "                    \"vendor\"\n",
    "                ]\n",
    "            )\n",
    "mce_his = pd.DataFrame(\n",
    "                [],\n",
    "                columns=[\n",
    "                    \"serial_number\",\n",
    "                    \"mca_id\",\n",
    "                    \"transaction\",\n",
    "                    \"collect_time\",\n",
    "                    \"manufacturer\",\n",
    "                    \"vendor\"\n",
    "                ]\n",
    "            )  \n",
    "address_his = pd.DataFrame(\n",
    "                [],\n",
    "                columns=[\n",
    "                    \"serial_number\",\n",
    "                    \"memory\",\n",
    "                    \"rankid\",\n",
    "                    \"bankid\",\n",
    "                    \"row\",\n",
    "                    \"col\",\n",
    "                    \"collect_time\",\n",
    "                    \"manufacturer\",\n",
    "                    \"vendor\"\n",
    "                ]\n",
    "            )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(current_time):\n",
    "    global count\n",
    "    global kernel_his\n",
    "    global mce_his\n",
    "    global address_his\n",
    "    \n",
    "    try:\n",
    "        kernel_log = kernel_test_groupby.get_group(current_time)\n",
    "    except:\n",
    "        kernel_log = pd.DataFrame(\n",
    "                [],\n",
    "                columns=[\n",
    "                    \"collect_time\",\n",
    "                    \"1_hwerr_f\",\n",
    "                    \"1_hwerr_e\",\n",
    "                    \"2_hwerr_c\",\n",
    "                    \"2_sel\",\n",
    "                    \"3_hwerr_n\",\n",
    "                    \"2_hwerr_s\",\n",
    "                    \"3_hwerr_m\",\n",
    "                    \"1_hwerr_st\",\n",
    "                    \"1_hw_mem_c\",\n",
    "                    \"3_hwerr_p\",\n",
    "                    \"2_hwerr_ce\",\n",
    "                    \"3_hwerr_as\",\n",
    "                    \"1_ke\",\n",
    "                    \"2_hwerr_p\",\n",
    "                    \"3_hwerr_kp\",\n",
    "                    \"1_hwerr_fl\",\n",
    "                    \"3_hwerr_r\",\n",
    "                    \"_hwerr_cd\",\n",
    "                    \"3_sup_mce_note\",\n",
    "                    \"3_cmci_sub\",\n",
    "                    \"3_cmci_det\",\n",
    "                    \"3_hwerr_pi\",\n",
    "                    \"3_hwerr_o\",\n",
    "                    \"3_hwerr_mce_l\",\n",
    "                    \"serial_number\",\n",
    "                    \"manufacturer\",\n",
    "                    \"vendor\"\n",
    "                ]\n",
    "            )\n",
    "    try:\n",
    "        mce_log = mce_test_groupby.get_group(current_time)\n",
    "    except:\n",
    "        mce_log = pd.DataFrame(\n",
    "                [],\n",
    "                columns=[\n",
    "                    \"serial_number\",\n",
    "                    \"mca_id\",\n",
    "                    \"transaction\",\n",
    "                    \"collect_time\",\n",
    "                    \"manufacturer\",\n",
    "                    \"vendor\"\n",
    "                ]\n",
    "            ) \n",
    "    try:\n",
    "        address_log = address_test_groupby.get_group(current_time)\n",
    "    except:\n",
    "        address_log = pd.DataFrame(\n",
    "                [],\n",
    "                columns=[\n",
    "                    \"serial_number\",\n",
    "                    \"memory\",\n",
    "                    \"rankid\",\n",
    "                    \"bankid\",\n",
    "                    \"row\",\n",
    "                    \"col\",\n",
    "                    \"collect_time\",\n",
    "                    \"manufacturer\",\n",
    "                    \"vendor\"\n",
    "                ]\n",
    "            ) \n",
    "\n",
    "    count += 1\n",
    "    \n",
    "    for i in kernel_var:\n",
    "        kernel_log[i] = kernel_log[i].map(deal_bool)\n",
    "    \n",
    "    kernel_his = pd.concat([kernel_his,kernel_log],ignore_index=True)\n",
    "    mce_his = pd.concat([mce_his,mce_log],ignore_index=True)\n",
    "    address_his = pd.concat([address_his,address_log],ignore_index=True)\n",
    "    if kernel_log.shape[0] != 0 and count%2 == 0:\n",
    "        test_data = get_data(kernel_his,mce_his,address_his)\n",
    "        kernel_his = pd.DataFrame(\n",
    "                [],\n",
    "                columns=[\n",
    "                    \"collect_time\",\n",
    "                    \"1_hwerr_f\",\n",
    "                    \"1_hwerr_e\",\n",
    "                    \"2_hwerr_c\",\n",
    "                    \"2_sel\",\n",
    "                    \"3_hwerr_n\",\n",
    "                    \"2_hwerr_s\",\n",
    "                    \"3_hwerr_m\",\n",
    "                    \"1_hwerr_st\",\n",
    "                    \"1_hw_mem_c\",\n",
    "                    \"3_hwerr_p\",\n",
    "                    \"2_hwerr_ce\",\n",
    "                    \"3_hwerr_as\",\n",
    "                    \"1_ke\",\n",
    "                    \"2_hwerr_p\",\n",
    "                    \"3_hwerr_kp\",\n",
    "                    \"1_hwerr_fl\",\n",
    "                    \"3_hwerr_r\",\n",
    "                    \"_hwerr_cd\",\n",
    "                    \"3_sup_mce_note\",\n",
    "                    \"3_cmci_sub\",\n",
    "                    \"3_cmci_det\",\n",
    "                    \"3_hwerr_pi\",\n",
    "                    \"3_hwerr_o\",\n",
    "                    \"3_hwerr_mce_l\",\n",
    "                    \"serial_number\",\n",
    "                    \"manufacturer\",\n",
    "                    \"vendor\"\n",
    "                ]\n",
    "            )\n",
    "        mce_his = pd.DataFrame(\n",
    "                [],\n",
    "                columns=[\n",
    "                    \"serial_number\",\n",
    "                    \"mca_id\",\n",
    "                    \"transaction\",\n",
    "                    \"collect_time\",\n",
    "                    \"manufacturer\",\n",
    "                    \"vendor\"\n",
    "                ]\n",
    "            )  \n",
    "        address_his = pd.DataFrame(\n",
    "                [],\n",
    "                columns=[\n",
    "                    \"serial_number\",\n",
    "                    \"memory\",\n",
    "                    \"rankid\",\n",
    "                    \"bankid\",\n",
    "                    \"row\",\n",
    "                    \"col\",\n",
    "                    \"collect_time\",\n",
    "                    \"manufacturer\",\n",
    "                    \"vendor\"\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    else:\n",
    "        test_data = pd.DataFrame()\n",
    "            \n",
    "    res = predict(test_data)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = ProcessPool(10)\n",
    "\n",
    "current_time = pd.to_datetime('2019-07-22')\n",
    "time_list = []\n",
    "\n",
    "while current_time < pd.to_datetime('2019-08-01'):\n",
    "    time_list.append(current_time)\n",
    "    current_time = current_time + timedelta(minutes=1)\n",
    "\n",
    "res = pool.map(run, time_list)\n",
    "\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([i for i in res], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = pd.to_datetime('20190722')\n",
    "end = start + timedelta(days=10)\n",
    "fail = failure_data[(failure_data['failure_time']>=start)&(failure_data['failure_time']<end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['collect_time'] = pd.to_datetime(result['collect_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24012646858213066"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_func_round2(result, fail, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
